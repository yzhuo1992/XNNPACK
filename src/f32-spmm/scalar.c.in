// Copyright 2019 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$ABC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
#include <assert.h>

#include <xnnpack/math.h>
#include <xnnpack/spmm.h>


void xnn_f32_spmm_minmax_ukernel_${MR}x${NR}__scalar${"_x" + str(UNROLL) if UNROLL > 1 else ""}(
    uint32_t batch_size,
    uint32_t output_channels,
    const float*restrict input,
    const float*restrict weights,
    const int32_t*restrict widx_dmap,
    const uint32_t*restrict nidx_nnzmap,
    float*restrict output,
    const union xnn_f32_minmax_params params[restrict XNN_MIN_ELEMENTS(1)])
{
  assert(batch_size != 0);

  const uintptr_t output_stride = ${NR} * batch_size * sizeof(float);
  const float vmin = params->scalar.min;
  const float vmax = params->scalar.max;
  size_t n = batch_size;
  while (n >= ${MR}) {
    const float*restrict w = weights;
    const int32_t* dmap = widx_dmap;
    const uint32_t* nnzmap = nidx_nnzmap;
    size_t c = output_channels;
    while (c >= ${NR}) {
      uint32_t nnz = *nnzmap++;
      $for N in range(0, NR, 1):
        float vacc0x${N} = *w++;
        $for M in range(1, MR):
          float vacc${ABC[M]}x${N} = vacc0x${N};
      if XNN_LIKELY(nnz != 0) {
        do {
          const intptr_t diff = *dmap++;
          $for M in range(MR):
            const float vi${ABC[M]} = input[${M}];
          input = (const float*restrict) ((uintptr_t) input + (uintptr_t) diff);
          $for N in range(0, NR, 1):
            const float vw${N} = *w++;
          $for N in range(0, NR, 1):
            $for M in range(MR):
              vacc${ABC[M]}x${N} += vi${ABC[M]} * vw${N};
        } while (--nnz != 0);
      }
      $for N in range(NR):
        $for M in range(MR):
          float vout${ABC[M]}x${N} = math_min_f32(vacc${ABC[M]}x${N}, vmax);
      $for N in range(NR):
        $for M in range(MR):
          vout${ABC[M]}x${N} = math_max_f32(vout${ABC[M]}x${N}, vmin);
      $for N in range(NR):
        $for M in range(MR):
          output[${N} * batch_size + ${M}] = vout${ABC[M]}x${N};
      output = (float*restrict) ((uintptr_t) output + output_stride);
      c -= ${NR};
    }
    if XNN_UNLIKELY(c != 0) {
      do {
        uint32_t nnz = *nnzmap++;
        float vacc0 = *w++;
        $for M in range(1, MR):
          float vacc${ABC[M]} = vacc0;
        if XNN_LIKELY(nnz != 0) {
          do {
            const intptr_t diff = *dmap++;
            $for M in range(MR):
              const float vi${ABC[M]} = input[${M}];
            input = (const float*restrict) ((uintptr_t) input + (uintptr_t) diff);
            const float vw = *w++;
            $for M in range(MR):
              vacc${ABC[M]} += vi${ABC[M]} * vw;
          } while (--nnz != 0);
        }
        $for M in range(MR):
          float vout${ABC[M]} = math_min_f32(vacc${ABC[M]}, vmax);
        $for M in range(MR):
          vout${ABC[M]} = math_max_f32(vout${ABC[M]}, vmin);
        $for M in range(MR):
          output[${M}] = vout${ABC[M]};
        output += batch_size;
        c -= 1;
      } while (c != 0);
    }
    output -= batch_size * output_channels;
    output += ${MR};
    input += ${MR};
    n -= ${MR};
  }
  if XNN_UNLIKELY(n != 0) {
    $for LOG2M in reversed(range((MR - 1).bit_length())):
      $SUBMR = 1 << LOG2M
      if (n & ${SUBMR}) {
        const float*restrict w = weights;
        const int32_t* dmap = widx_dmap;
        const uint32_t* nnzmap = nidx_nnzmap;
        size_t c = output_channels;
        while (c >= ${NR}) {
          uint32_t nnz = *nnzmap++;
          $for N in range(0, NR, 1):
            float vacc0x${N} = *w++;
            $for M in range(1, SUBMR):
              float vacc${ABC[M]}x${N} = vacc0x${N};
          if XNN_LIKELY(nnz != 0) {
            do {
              const intptr_t diff = *dmap++;
              $for M in range(SUBMR):
                const float vi${ABC[M]} = input[${M}];
              input = (const float*restrict) ((uintptr_t) input + (uintptr_t) diff);
              $for N in range(0, NR, 1):
                const float vw${N} = *w++;
              $for N in range(0, NR, 1):
                $for M in range(SUBMR):
                  vacc${ABC[M]}x${N} += vi${ABC[M]} * vw${N};
            } while (--nnz != 0);
          }
          $for N in range(0, NR, 1):
            $for M in range(SUBMR):
              float vout${ABC[M]}x${N} = math_min_f32(vacc${ABC[M]}x${N}, vmax);
          $for N in range(0, NR, 1):
            $for M in range(SUBMR):
              vout${ABC[M]}x${N} = math_max_f32(vout${ABC[M]}x${N}, vmin);
          $for N in range(0, NR, 1):
            $for M in range(SUBMR):
              output[${N} * batch_size + ${M}] = vout${ABC[M]}x${N};
          output = (float*restrict) ((uintptr_t) output + output_stride);
          c -= ${NR};
        }
        if XNN_UNLIKELY(c != 0) {
          do {
            uint32_t nnz = *nnzmap++;
            float vacc0 = *w++;
            $for M in range(1, SUBMR):
              float vacc${ABC[M]} = vacc0;
            if XNN_LIKELY(nnz != 0) {
              do {
                const intptr_t diff = *dmap++;
                $for M in range(SUBMR):
                  const float vi${ABC[M]} = input[${M}];
                input = (const float*restrict) ((uintptr_t) input + (uintptr_t) diff);
                const float vw = *w++;
                $for M in range(SUBMR):
                  vacc${ABC[M]} += vi${ABC[M]} * vw;
              } while (--nnz != 0);
            }
            $for M in range(SUBMR):
              float vout${ABC[M]} = math_min_f32(vacc${ABC[M]}, vmax);
            $for M in range(SUBMR):
              vout${ABC[M]} = math_max_f32(vout${ABC[M]}, vmin);
            $for M in range(SUBMR):
              output[${M}] = vout${ABC[M]};
            output += batch_size;
            c -= 1;
          } while (c != 0);
        }
        output -= batch_size * output_channels;
        output += ${SUBMR};
        input += ${SUBMR};
      }
  }
}
